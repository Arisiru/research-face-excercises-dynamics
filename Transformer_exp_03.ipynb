{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ffceac",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941fce85",
   "metadata": {},
   "source": [
    "Third iteration on the data - build transformer\n",
    "- read data from json \n",
    "- a training/test split shall be based on patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2167fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2277c",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb75db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 500\n",
    "\n",
    "X_MAX = 362.850308418274\n",
    "X_MIN = -385.386139154434\n",
    "Y_MAX = 407.209008932114\n",
    "Y_MIN = -184.533506631851\n",
    "Z_MAX = 1414.35980796814\n",
    "Z_MIN = 465.504199266434\n",
    "\n",
    "N_CLASSES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d69a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = {\n",
    "    '0_LefteyeMidbottom': 'orbital', \n",
    "    '1_LefteyeMidtop': 'orbital',  \n",
    "    '2_LefteyeInnercorner': 'orbital', \n",
    "    '3_LefteyeOutercorner': 'orbital',  \n",
    "    '4_LefteyebrowInner': 'frontal', \n",
    "    '5_LefteyebrowCenter': 'frontal',  \n",
    "    '6_RighteyeMidbottom': 'orbital',  \n",
    "    '7_RighteyeMidtop': 'orbital', \n",
    "    '8_RighteyeInnercorner': 'orbital',  \n",
    "    '9_RighteyeOutercorner': 'orbital', \n",
    "    '10_RighteyebrowInner': 'frontal', \n",
    "    '11_RighteyebrowCenter': 'frontal',  \n",
    "    '12_NoseTip': 'nasal', \n",
    "    '13_MouthLowerlipMidbottom': 'oral',\n",
    "    '14_MouthLeftcorner': 'oral',\n",
    "    '15_MouthRightcorner': 'oral',\n",
    "    '16_MouthUpperlipMidtop': 'oral',\n",
    "    '17_ChinCenter': 'other', \n",
    "    '18_ForeheadCenter': 'frontal', \n",
    "    '19_LeftcheekCenter': 'other', \n",
    "    '20_RightcheekCenter': 'other',\n",
    "}\n",
    "\n",
    "pois_order = {\n",
    "    '0_LefteyeMidbottom': 0,\n",
    "    '1_LefteyeMidtop': 1,\n",
    "    '2_LefteyeInnercorner': 2,\n",
    "    '3_LefteyeOutercorner': 3,  \n",
    "    '6_RighteyeMidbottom': 4,  \n",
    "    '7_RighteyeMidtop': 5,\n",
    "    '8_RighteyeInnercorner': 6,  \n",
    "    '9_RighteyeOutercorner': 7,\n",
    "    '4_LefteyebrowInner': 8,\n",
    "    '5_LefteyebrowCenter': 8,\n",
    "    '18_ForeheadCenter': 10,\n",
    "    '10_RighteyebrowInner': 11,\n",
    "    '11_RighteyebrowCenter': 12,\n",
    "    '12_NoseTip': 13,\n",
    "    '13_MouthLowerlipMidbottom': 14,\n",
    "    '14_MouthLeftcorner': 15,\n",
    "    '15_MouthRightcorner': 16,\n",
    "    '16_MouthUpperlipMidtop': 17,\n",
    "    '17_ChinCenter': 18,\n",
    "    '19_LeftcheekCenter': 19,\n",
    "    '20_RightcheekCenter': 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed45b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data_root = os.path.join('data')\n",
    "dir_data_source = os.path.join(dir_data_root, 'json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544c090",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab6ece",
   "metadata": {},
   "source": [
    "Read every patien file in the target directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "256cd9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for patient ID: 00000000082\n",
      "Loaded data for patient ID: 00000000057\n",
      "Loaded data for patient ID: 00000000000\n",
      "Loaded data for patient ID: 00000000016\n",
      "Loaded data for patient ID: 00000000041\n",
      "Loaded data for patient ID: 00000000036\n",
      "Loaded data for patient ID: 00000000061\n",
      "Loaded data for patient ID: 00000000077\n",
      "Loaded data for patient ID: 00000000020\n",
      "Loaded data for patient ID: 00000000076\n",
      "Loaded data for patient ID: 00000000060\n",
      "Loaded data for patient ID: 00000000037\n",
      "Loaded data for patient ID: 00000000040\n",
      "Loaded data for patient ID: 00000000017\n",
      "Loaded data for patient ID: 00000000001\n",
      "Loaded data for patient ID: 00000000056\n",
      "Loaded data for patient ID: 00000000083\n",
      "Loaded data for patient ID: 00000000030\n",
      "Loaded data for patient ID: 00000000067\n",
      "Loaded data for patient ID: 00000000071\n",
      "Loaded data for patient ID: 00000000026\n",
      "Loaded data for patient ID: 00000000051\n",
      "Loaded data for patient ID: 00000000006\n",
      "Loaded data for patient ID: 00000000010\n",
      "Loaded data for patient ID: 00000000047\n",
      "Loaded data for patient ID: 00000000046\n",
      "Loaded data for patient ID: 00000000011\n",
      "Loaded data for patient ID: 00000000007\n",
      "Loaded data for patient ID: 00000000050\n",
      "Loaded data for patient ID: 00000000085\n",
      "Loaded data for patient ID: 00000000027\n",
      "Loaded data for patient ID: 00000000070\n",
      "Loaded data for patient ID: 00000000066\n",
      "Loaded data for patient ID: 00000000031\n",
      "Loaded data for patient ID: 00000000049\n",
      "Loaded data for patient ID: 00000000008\n",
      "Loaded data for patient ID: 00000000073\n",
      "Loaded data for patient ID: 00000000065\n",
      "Loaded data for patient ID: 00000000032\n",
      "Loaded data for patient ID: 00000000045\n",
      "Loaded data for patient ID: 00000000012\n",
      "Loaded data for patient ID: 00000000004\n",
      "Loaded data for patient ID: 00000000053\n",
      "Loaded data for patient ID: 00000000028\n",
      "Loaded data for patient ID: 00000000069\n",
      "Loaded data for patient ID: 00000000068\n",
      "Loaded data for patient ID: 00000000029\n",
      "Loaded data for patient ID: 00000000052\n",
      "Loaded data for patient ID: 00000000005\n",
      "Loaded data for patient ID: 00000000013\n",
      "Loaded data for patient ID: 00000000044\n",
      "Loaded data for patient ID: 00000000033\n",
      "Loaded data for patient ID: 00000000064\n",
      "Loaded data for patient ID: 00000000072\n",
      "Loaded data for patient ID: 00000000025\n",
      "Loaded data for patient ID: 00000000009\n",
      "Loaded data for patient ID: 00000000048\n",
      "Loaded data for patient ID: 00000000043\n",
      "Loaded data for patient ID: 00000000014\n",
      "Loaded data for patient ID: 00000000002\n",
      "Loaded data for patient ID: 00000000055\n",
      "Loaded data for patient ID: 00000000079\n",
      "Loaded data for patient ID: 00000000080\n",
      "Loaded data for patient ID: 00000000038\n",
      "Loaded data for patient ID: 00000000018\n",
      "Loaded data for patient ID: 00000000059\n",
      "Loaded data for patient ID: 00000000022\n",
      "Loaded data for patient ID: 00000000075\n",
      "Loaded data for patient ID: 00000000063\n",
      "Loaded data for patient ID: 00000000034\n",
      "Loaded data for patient ID: 00000000035\n",
      "Loaded data for patient ID: 00000000074\n",
      "Loaded data for patient ID: 00000000023\n",
      "Loaded data for patient ID: 00000000058\n",
      "Loaded data for patient ID: 00000000019\n",
      "Loaded data for patient ID: 00000000039\n",
      "Loaded data for patient ID: 00000000081\n",
      "Loaded data for patient ID: 00000000078\n",
      "Loaded data for patient ID: 00000000003\n",
      "Loaded data for patient ID: 00000000015\n",
      "Loaded data for patient ID: 00000000042\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for file_name in os.listdir(dir_data_source):\n",
    "    \n",
    "    patient_id = file_name.split('.')[0]\n",
    "    with open(os.path.join(dir_data_source, file_name)) as f:\n",
    "        data[patient_id] = json.load(f)\n",
    "        \n",
    "        print('Loaded data for patient ID: %s' % patient_id)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2029f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = list(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda87fc2",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5783fd9e",
   "metadata": {},
   "source": [
    "## Data set per session"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91aa8d7d",
   "metadata": {},
   "source": [
    "session = {\n",
    "    'meta': {\n",
    "        'patient_id': str,\n",
    "        'exercise_dates': str,\n",
    "        'evaluation': int,\n",
    "        'flag_before_surgery': flag_before_surgery,\n",
    "    }\n",
    "    'exercises': [...]\n",
    "}\n",
    "\n",
    "exercise_data = {\n",
    "    'meta': {\n",
    "        'tag': str\n",
    "        'id': int\n",
    "        'name': str\n",
    "    },\n",
    "    'pois': [...]\n",
    "}\n",
    "poi_data = {\n",
    "    'meta': {\n",
    "        'tag': str\n",
    "        'id': int\n",
    "        'name': str\n",
    "        'region': str\n",
    "    },\n",
    "    'input': {\n",
    "        'x': []\n",
    "        'y': []\n",
    "        'z': []\n",
    "        'dist': []\n",
    "        'x_normalized': []\n",
    "        'y_normalized': []\n",
    "        'z_normalized': []\n",
    "        'dist_normalized': []\n",
    "        'direction_angles': []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8117bac7",
   "metadata": {},
   "source": [
    "## Data obseravation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7380378",
   "metadata": {},
   "source": [
    "Get length of all measurements individualy at POIs levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f7d62b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_pois(poi):\n",
    "    return pois_order[poi['meta']['tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52afa3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_lens = []\n",
    "for patient_id in data:\n",
    "    for session in data[patient_id]:\n",
    "        #print(patient_id)\n",
    "        for excercise in session['exercises']: \n",
    "            xs_excercise = []\n",
    "            pois_sorted = sorted(excercise['pois'], key = key_pois)\n",
    "            for poi in pois_sorted:\n",
    "                #print(len(poi['input']['x_normalized']))\n",
    "                signal_lens.append(len(poi['input']['x_normalized']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8a15199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21609 sequences for pois\n"
     ]
    }
   ],
   "source": [
    "print('There are %s sequences for pois' % len(signal_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a257e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})\n",
    "\n",
    "# Plot Histogram on x\n",
    "x = signal_lens\n",
    "plt.hist(x)\n",
    "plt.gca().set(title='Frequency Histogram', ylabel='Frequency');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca3d18d",
   "metadata": {},
   "source": [
    "##### Build training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e93312c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85213ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(patients)\n",
    "\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e7fd90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_patients = patients[:72]\n",
    "validating_patients = []#patients[60:70]\n",
    "testing_patients = patients[72:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1b18dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_inputs(target_patients):\n",
    "    target_xs = []\n",
    "    target_ys = []\n",
    "    \n",
    "    for patient_id in target_patients:\n",
    "        #print('Extracting sessions for patient: %s' % patient_id)\n",
    "\n",
    "        for session in data[patient_id]:\n",
    "            for excercise in session['exercises']: \n",
    "                xs_excercise = []\n",
    "                pois_sorted = sorted(excercise['pois'], key = key_pois)\n",
    "                for poi in pois_sorted:\n",
    "                    #xs_excercise.append(poi['input']['x'])\n",
    "                    #xs_excercise.append(poi['input']['y'])\n",
    "                    #xs_excercise.append(poi['input']['z'])\n",
    "                    #xs_excercise.append(poi['input']['dist'])\n",
    "                    xs_excercise.append(poi['input']['x_normalized'])\n",
    "                    xs_excercise.append(poi['input']['y_normalized'])\n",
    "                    xs_excercise.append(poi['input']['z_normalized'])\n",
    "                    xs_excercise.append(poi['input']['dist_normalized'])\n",
    "                    xs_excercise.append(poi['input']['direction_angles'])\n",
    "                    break\n",
    "                target_xs.append(pad_sequences(\n",
    "                    xs_excercise,\n",
    "                    padding=\"pre\",\n",
    "                    dtype = 'f',\n",
    "                    maxlen=SEQ_LEN))\n",
    "                target_ys.append(session['meta']['evaluation'] - 1)\n",
    "                break\n",
    "            \n",
    "    return target_xs, target_ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983cafaa",
   "metadata": {},
   "source": [
    "### Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "17e5558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4e729188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 53, 1: 15, 2: 13, 5: 11, 3: 5, 4: 5})\n",
      "{0: 0.32075471698113206, 2: 1.3076923076923077, 1: 1.1333333333333333, 3: 3.4, 5: 1.5454545454545454, 4: 3.4}\n"
     ]
    }
   ],
   "source": [
    "_, classes_in_training = fill_inputs(training_patients)\n",
    "\n",
    "freq_training_classes = Counter(classes_in_training) \n",
    "\n",
    "print(freq_training_classes)\n",
    "\n",
    "weight_training_classes = {}\n",
    "for class_id in freq_training_classes:\n",
    "    weight_training_classes[class_id] = len(classes_in_training) / (N_CLASSES * freq_training_classes[class_id])\n",
    "\n",
    "print(weight_training_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a42e5",
   "metadata": {},
   "source": [
    "### Train, Val, Test sets generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a93a7a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 5, 500)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "xs_train, ys_train = fill_inputs(training_patients)\n",
    "\n",
    "xs_train = np.array(xs_train)\n",
    "ys_train = np.array(ys_train)\n",
    "\n",
    "print(xs_train.shape)\n",
    "print(ys_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1fccf8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "xs_val, ys_val = fill_inputs(validating_patients)\n",
    "xs_val = np.array(xs_val)\n",
    "ys_val = np.array(ys_val)\n",
    "\n",
    "print(xs_val.shape)\n",
    "print(ys_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dd802d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 5, 500)\n",
      "(17,)\n"
     ]
    }
   ],
   "source": [
    "xs_test, ys_test = fill_inputs(testing_patients)\n",
    "xs_test = np.array(xs_test)\n",
    "ys_test = np.array(ys_test)\n",
    "\n",
    "print(xs_test.shape)\n",
    "print(ys_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeba3312",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "db63f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2af8fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d4003dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(N_CLASSES, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d190d35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (5, 500)\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 5, 500)]     0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 5, 500)      1000        ['input_9[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 5, 500)      2051572     ['layer_normalization_16[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 5, 500)       0           ['multi_head_attention_8[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (TFOpL  (None, 5, 500)      0           ['dropout_18[0][0]',             \n",
      " ambda)                                                           'input_9[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 5, 500)      1000        ['tf.__operators__.add_16[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 5, 4)         2004        ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 5, 4)         0           ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 5, 500)       2500        ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (TFOpL  (None, 5, 500)      0           ['conv1d_17[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_16[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 5, 500)      1000        ['tf.__operators__.add_17[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 5, 500)      2051572     ['layer_normalization_18[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 5, 500)       0           ['multi_head_attention_9[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (TFOpL  (None, 5, 500)      0           ['dropout_20[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_17[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 5, 500)      1000        ['tf.__operators__.add_18[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 5, 4)         2004        ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 5, 4)         0           ['conv1d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 5, 500)       2500        ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (TFOpL  (None, 5, 500)      0           ['conv1d_19[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_18[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 5, 500)      1000        ['tf.__operators__.add_19[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 5, 500)      2051572     ['layer_normalization_20[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 5, 500)       0           ['multi_head_attention_10[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (TFOpL  (None, 5, 500)      0           ['dropout_22[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_19[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 5, 500)      1000        ['tf.__operators__.add_20[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 5, 4)         2004        ['layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 5, 4)         0           ['conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 5, 500)       2500        ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (TFOpL  (None, 5, 500)      0           ['conv1d_21[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_20[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 5, 500)      1000        ['tf.__operators__.add_21[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 5, 500)      2051572     ['layer_normalization_22[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 5, 500)       0           ['multi_head_attention_11[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (TFOpL  (None, 5, 500)      0           ['dropout_24[0][0]',             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ambda)                                                           'tf.__operators__.add_21[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 5, 500)      1000        ['tf.__operators__.add_22[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 5, 4)         2004        ['layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 5, 4)         0           ['conv1d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 5, 500)       2500        ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (TFOpL  (None, 5, 500)      0           ['conv1d_23[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_22[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 5)           0           ['tf.__operators__.add_23[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          768         ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 128)          0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 6)            774         ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,233,846\n",
      "Trainable params: 8,233,846\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alanchen/.local/share/virtualenvs/research-face-excercises-dynamics-o_HFBNSW/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_shape = xs_train.shape[1:]\n",
    "print('Input shape: %s' % (str(input_shape)))\n",
    "\n",
    "xs_input = layers.Input(shape=input_shape)\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#x = layers.LSTM(32, activation=\"relu\")(xs_input)\n",
    "#x = layers.Flatten()(xs_input)\n",
    "#x = layers.Dense(16, activation=\"relu\")(x)\n",
    "#x = layers.Dense(6)(x)\n",
    "#model = keras.Model(inputs=xs_input, outputs=x)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    optimizer=keras.optimizers.Adam(lr=1e-3, decay=1e-3 / 200),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6660fae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.4242 - accuracy: 0.8137\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.5674 - accuracy: 0.7157\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.4840 - accuracy: 0.7353\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.3363 - accuracy: 0.8627\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.4819 - accuracy: 0.7451\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.3996 - accuracy: 0.8235\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.8500 - accuracy: 0.8235\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.4247 - accuracy: 0.8137\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.5569 - accuracy: 0.7255\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.3227 - accuracy: 0.7745\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.3939 - accuracy: 0.7843\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.5622 - accuracy: 0.7451\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.4644 - accuracy: 0.8431\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.4065 - accuracy: 0.7549\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.5210 - accuracy: 0.7647\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.4165 - accuracy: 0.8235\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.4984 - accuracy: 0.7451\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.6064 - accuracy: 0.7255\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.4053 - accuracy: 0.7843\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.3694 - accuracy: 0.8431\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.3941 - accuracy: 0.7745\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.4148 - accuracy: 0.7843\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.3685 - accuracy: 0.8039\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.3653 - accuracy: 0.7941\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.5473 - accuracy: 0.7157\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.4250 - accuracy: 0.7157\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.3545 - accuracy: 0.8235\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.3596 - accuracy: 0.8529\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3493 - accuracy: 0.8137\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3604 - accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3231 - accuracy: 0.8529\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.4267 - accuracy: 0.8137\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.6126 - accuracy: 0.7549\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6922 - accuracy: 0.7255\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.4602 - accuracy: 0.7647\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.3362 - accuracy: 0.7941\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.4499 - accuracy: 0.8137\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.3443 - accuracy: 0.8137\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.3564 - accuracy: 0.8039\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.3409 - accuracy: 0.7941\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.2879 - accuracy: 0.8529\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.4316 - accuracy: 0.8235\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.3154 - accuracy: 0.8039\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.3057 - accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.3476 - accuracy: 0.8235\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.4231 - accuracy: 0.8529\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3288 - accuracy: 0.8431\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.3219 - accuracy: 0.8627\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.4109 - accuracy: 0.7549\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.2981 - accuracy: 0.8431\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.2755 - accuracy: 0.8529\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.2702 - accuracy: 0.8627\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3010 - accuracy: 0.8627\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.2815 - accuracy: 0.8824\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3743 - accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.3582 - accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3211 - accuracy: 0.7941\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.3268 - accuracy: 0.8039\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.3057 - accuracy: 0.8627\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.2861 - accuracy: 0.8235\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.2445 - accuracy: 0.8529\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.2982 - accuracy: 0.8922\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1893 - accuracy: 0.9412\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.2616 - accuracy: 0.9020\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.3168 - accuracy: 0.8529\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.2366 - accuracy: 0.8529\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.2320 - accuracy: 0.8529\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.2144 - accuracy: 0.9412\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.2731 - accuracy: 0.8824\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.2376 - accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.2318 - accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.1890 - accuracy: 0.9020\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.2096 - accuracy: 0.9314\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.5013 - accuracy: 0.8529\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.2650 - accuracy: 0.8235\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.3644 - accuracy: 0.8529\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.2159 - accuracy: 0.8922\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.3470 - accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.3501 - accuracy: 0.8627\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.2534 - accuracy: 0.8824\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.2482 - accuracy: 0.8529\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.3058 - accuracy: 0.8922\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 112ms/step - loss: 0.2688 - accuracy: 0.8431\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.2765 - accuracy: 0.8725\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.4756 - accuracy: 0.7549\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.3563 - accuracy: 0.8725\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.3522 - accuracy: 0.8431\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3732 - accuracy: 0.7843\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.3274 - accuracy: 0.8529\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.4139 - accuracy: 0.7745\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.2163 - accuracy: 0.8627\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.4091 - accuracy: 0.7353\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.2662 - accuracy: 0.8627\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.3224 - accuracy: 0.8137\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.2528 - accuracy: 0.8725\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.2489 - accuracy: 0.8529\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.2318 - accuracy: 0.8922\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.2220 - accuracy: 0.8824\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.2848 - accuracy: 0.8529\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.2256 - accuracy: 0.8922\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.2582 - accuracy: 0.8725\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.2967 - accuracy: 0.8431\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.2018 - accuracy: 0.9412\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.1867 - accuracy: 0.9118\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.1057 - accuracy: 0.9608\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.1238 - accuracy: 0.9314\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0979 - accuracy: 0.9902\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.1625 - accuracy: 0.9314\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.1148 - accuracy: 0.9608\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.1438 - accuracy: 0.9216\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.1781 - accuracy: 0.9020\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.1131 - accuracy: 0.9608\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.1206 - accuracy: 0.9216\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.1898 - accuracy: 0.9314\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.1427 - accuracy: 0.9314\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1359 - accuracy: 0.9020\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.1723 - accuracy: 0.8922\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.2090 - accuracy: 0.9216\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.1985 - accuracy: 0.9020\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.2086 - accuracy: 0.9118\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.1779 - accuracy: 0.9216\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.1945 - accuracy: 0.8824\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.1617 - accuracy: 0.9412\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.2198 - accuracy: 0.8922\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.2415 - accuracy: 0.9216\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.1353 - accuracy: 0.9118\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.1851 - accuracy: 0.9118\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.1913 - accuracy: 0.8824\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.1665 - accuracy: 0.9118\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.1866 - accuracy: 0.9314\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.1475 - accuracy: 0.9314\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1133 - accuracy: 0.9510\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.1843 - accuracy: 0.9020\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.1662 - accuracy: 0.9216\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.1076 - accuracy: 0.9412\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.1442 - accuracy: 0.9118\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1031 - accuracy: 0.9510\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.1289 - accuracy: 0.9314\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.1254 - accuracy: 0.9412\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.1089 - accuracy: 0.9510\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1193 - accuracy: 0.9510\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1111 - accuracy: 0.9216\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.1486 - accuracy: 0.9216\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.1292 - accuracy: 0.9020\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0580 - accuracy: 0.9510\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.1743 - accuracy: 0.9020\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0742 - accuracy: 0.9706\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0642 - accuracy: 0.9706\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1189 - accuracy: 0.9314\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1103 - accuracy: 0.9412\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0723 - accuracy: 0.9804\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.1064 - accuracy: 0.9412\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0939 - accuracy: 0.9118\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.1386 - accuracy: 0.9412\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0806 - accuracy: 0.9412\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0934 - accuracy: 0.9510\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.1091 - accuracy: 0.9706\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.1058 - accuracy: 0.9608\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.1154 - accuracy: 0.9510\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.1624 - accuracy: 0.9020\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0842 - accuracy: 0.9510\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0804 - accuracy: 0.9804\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.2078 - accuracy: 0.9510\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0735 - accuracy: 0.9706\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.1115 - accuracy: 0.9510\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.1321 - accuracy: 0.9412\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0976 - accuracy: 0.9804\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.1945 - accuracy: 0.9510\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.1096 - accuracy: 0.9510\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.1904 - accuracy: 0.9608\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.0805 - accuracy: 0.9706\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0623 - accuracy: 0.9804\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0677 - accuracy: 0.9608\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0645 - accuracy: 0.9706\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1126 - accuracy: 0.9608\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.2000 - accuracy: 0.9510\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0992 - accuracy: 0.9608\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.1314 - accuracy: 0.8824\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0816 - accuracy: 0.9510\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.1250 - accuracy: 0.9412\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0966 - accuracy: 0.9412\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.1400 - accuracy: 0.9216\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1234 - accuracy: 0.9412\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1361 - accuracy: 0.9216\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0724 - accuracy: 0.9902\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0765 - accuracy: 0.9902\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0702 - accuracy: 0.9412\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0513 - accuracy: 0.9706\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.0543 - accuracy: 0.9608\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0999 - accuracy: 0.9608\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.0617 - accuracy: 0.9902\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.1346 - accuracy: 0.9706\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0745 - accuracy: 0.9510\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0454 - accuracy: 0.9706\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.1715 - accuracy: 0.9216\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.1466 - accuracy: 0.9216\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0928 - accuracy: 0.9314\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.1045 - accuracy: 0.9608\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0657 - accuracy: 0.9608\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0795 - accuracy: 0.9706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3d3694c70>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    xs_train,\n",
    "    ys_train,\n",
    "    #validation_data=(xs_val, ys_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    #callbacks=callbacks,\n",
    "    class_weight=weight_training_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "caa42cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 5, 500)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "65b98537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 21:54:38.109982: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 1s - loss: 12.3817 - accuracy: 0.1765 - 685ms/epoch - 685ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.381667137145996, 0.1764705926179886]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xs_test, ys_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0e2d31b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 21:54:38.799268: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 514ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.20      0.25         5\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.18        17\n",
      "   macro avg       0.10      0.12      0.10        17\n",
      "weighted avg       0.17      0.18      0.16        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alanchen/.local/share/virtualenvs/research-face-excercises-dynamics-o_HFBNSW/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/alanchen/.local/share/virtualenvs/research-face-excercises-dynamics-o_HFBNSW/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/alanchen/.local/share/virtualenvs/research-face-excercises-dynamics-o_HFBNSW/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/alanchen/.local/share/virtualenvs/research-face-excercises-dynamics-o_HFBNSW/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/alanchen/.local/share/virtualenvs/research-face-excercises-dynamics-o_HFBNSW/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/alanchen/.local/share/virtualenvs/research-face-excercises-dynamics-o_HFBNSW/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(xs_test, batch_size=8, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(ys_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0e16f8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.51223065e-02, 8.13481105e-09, 2.73521655e-05, 1.18203280e-09,\n",
       "        4.11051745e-03, 9.80739832e-01],\n",
       "       [8.49573731e-01, 3.82921584e-02, 9.77483168e-02, 6.54317701e-05,\n",
       "        8.20849527e-06, 1.43121416e-02],\n",
       "       [1.48190102e-02, 9.89236426e-09, 2.99726871e-05, 1.06367748e-09,\n",
       "        3.09361564e-03, 9.82057452e-01],\n",
       "       [4.07170365e-03, 8.00541800e-10, 6.95875585e-02, 3.37780136e-07,\n",
       "        6.97103202e-01, 2.29237139e-01],\n",
       "       [9.97612596e-01, 2.74653605e-04, 2.11255392e-03, 2.26745087e-15,\n",
       "        7.77312818e-15, 1.47845000e-07],\n",
       "       [4.47751358e-02, 8.72171223e-01, 8.30435008e-02, 2.70830469e-06,\n",
       "        8.62710403e-10, 7.49804212e-06],\n",
       "       [1.90771278e-02, 1.27181847e-05, 1.98732642e-03, 2.64275532e-05,\n",
       "        2.89272040e-01, 6.89624369e-01],\n",
       "       [1.40062077e-02, 5.87604927e-06, 1.19623251e-03, 1.29837308e-05,\n",
       "        3.15351099e-01, 6.69427633e-01],\n",
       "       [1.00000000e+00, 7.57765754e-15, 2.68285588e-10, 5.51681910e-29,\n",
       "        1.15380387e-29, 4.12278795e-17],\n",
       "       [4.33399139e-13, 1.32107671e-05, 8.61328954e-05, 9.99900579e-01,\n",
       "        2.08383213e-15, 2.52443260e-18],\n",
       "       [7.82938805e-05, 9.88304853e-01, 1.12857549e-02, 3.31028219e-04,\n",
       "        1.06162568e-09, 3.84654086e-08],\n",
       "       [1.08736781e-02, 3.20179265e-06, 7.55986141e-04, 7.69758390e-06,\n",
       "        2.92403877e-01, 6.95955455e-01],\n",
       "       [1.50710186e-02, 2.77431354e-07, 2.01633287e-04, 1.68995371e-07,\n",
       "        4.75919247e-02, 9.37134981e-01],\n",
       "       [2.32231287e-05, 1.68217090e-12, 4.90460070e-06, 2.29832736e-10,\n",
       "        9.89183068e-01, 1.07886689e-02],\n",
       "       [8.90350566e-05, 5.00547563e-12, 1.56902004e-07, 4.15282253e-11,\n",
       "        6.95653856e-01, 3.04256946e-01],\n",
       "       [4.47950959e-02, 9.91499718e-08, 1.27776817e-04, 6.60989175e-09,\n",
       "        1.81541906e-03, 9.53261614e-01],\n",
       "       [4.78101720e-06, 3.02903759e-14, 4.02266398e-09, 5.97701576e-13,\n",
       "        8.94810259e-01, 1.05184987e-01]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde8e3db",
   "metadata": {},
   "source": [
    "__END__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face-prognosis",
   "language": "python",
   "name": "face-prognosis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
