{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ffceac",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941fce85",
   "metadata": {},
   "source": [
    "The data processing iteration focus to extract input from the raw csv\n",
    "- every patient is a json\n",
    "- every session in an entry in patien object\n",
    "- every exercise is an entry in a session entry\n",
    "- every poi is an entry in an exercise object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564abfea",
   "metadata": {},
   "source": [
    "## Object shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91aa8d7d",
   "metadata": {},
   "source": [
    "session = {\n",
    "    'meta': {\n",
    "        'patient_id': str,\n",
    "        'exercise_dates': str,\n",
    "        'evaluation': int,\n",
    "        'flag_before_surgery': flag_before_surgery,\n",
    "    }\n",
    "    'exercises': [...]\n",
    "}\n",
    "\n",
    "exercise_data = {\n",
    "    'meta': {\n",
    "        'tag': str\n",
    "        'id': int\n",
    "        'name': str\n",
    "    },\n",
    "    'pois': [...]\n",
    "}\n",
    "poi_data = {\n",
    "    'meta': {\n",
    "        'tag': str\n",
    "        'id': int\n",
    "        'name': str\n",
    "        'region': str\n",
    "        'base': str (tag of POI to rebase against)\n",
    "    },\n",
    "    'input': {\n",
    "        'ts': []\n",
    "        'xs': []\n",
    "        'ys': []\n",
    "        'zs': []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2167fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed45b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data_root = os.path.join('data')\n",
    "dir_data_source = os.path.join(dir_data_root, 'csv')\n",
    "dir_data_target = os.path.join(dir_data_root, 'json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544c090",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c9fe9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = {\n",
    "    '0_LefteyeMidbottom': 'orbital', \n",
    "    '1_LefteyeMidtop': 'orbital',  \n",
    "    '2_LefteyeInnercorner': 'orbital', \n",
    "    '3_LefteyeOutercorner': 'orbital',  \n",
    "    '4_LefteyebrowInner': 'frontal', \n",
    "    '5_LefteyebrowCenter': 'frontal',  \n",
    "    '6_RighteyeMidbottom': 'orbital',  \n",
    "    '7_RighteyeMidtop': 'orbital', \n",
    "    '8_RighteyeInnercorner': 'orbital',  \n",
    "    '9_RighteyeOutercorner': 'orbital', \n",
    "    '10_RighteyebrowInner': 'frontal', \n",
    "    '11_RighteyebrowCenter': 'frontal',  \n",
    "    '12_NoseTip': 'frontal', \n",
    "    '13_MouthLowerlipMidbottom': 'oral',\n",
    "    '14_MouthLeftcorner': 'oral',\n",
    "    '15_MouthRightcorner': 'oral',\n",
    "    '16_MouthUpperlipMidtop': 'oral',\n",
    "    '17_ChinCenter': 'oral', \n",
    "    '18_ForeheadCenter': 'frontal', \n",
    "    '19_LeftcheekCenter': 'oral', \n",
    "    '20_RightcheekCenter': 'oral',\n",
    "}\n",
    "base = {\n",
    "    '0_LefteyeMidbottom': '18_ForeheadCenter', \n",
    "    '1_LefteyeMidtop': '18_ForeheadCenter',  \n",
    "    '2_LefteyeInnercorner': '18_ForeheadCenter', \n",
    "    '3_LefteyeOutercorner': '18_ForeheadCenter',  \n",
    "    '4_LefteyebrowInner': '18_ForeheadCenter', \n",
    "    '5_LefteyebrowCenter': '18_ForeheadCenter',  \n",
    "    '6_RighteyeMidbottom': '18_ForeheadCenter',  \n",
    "    '7_RighteyeMidtop': '18_ForeheadCenter', \n",
    "    '8_RighteyeInnercorner': '18_ForeheadCenter',  \n",
    "    '9_RighteyeOutercorner': '18_ForeheadCenter', \n",
    "    '10_RighteyebrowInner': '18_ForeheadCenter', \n",
    "    '11_RighteyebrowCenter': '18_ForeheadCenter',  \n",
    "    '12_NoseTip': '18_ForeheadCenter', \n",
    "    '13_MouthLowerlipMidbottom': '18_ForeheadCenter',\n",
    "    '14_MouthLeftcorner': '18_ForeheadCenter',\n",
    "    '15_MouthRightcorner': '18_ForeheadCenter',\n",
    "    '16_MouthUpperlipMidtop': '18_ForeheadCenter',\n",
    "    '17_ChinCenter': '18_ForeheadCenter', \n",
    "    '18_ForeheadCenter': 'base', \n",
    "    '19_LeftcheekCenter': '18_ForeheadCenter', \n",
    "    '20_RightcheekCenter': '18_ForeheadCenter',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f02512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_to_metadata(file_name):\n",
    "    meta = file_name.split(' ')\n",
    "    patient_id = meta[0]\n",
    "    try:\n",
    "        exercise_dates = datetime.strptime(re.sub(r'\\_[0-9]', '', meta[1]), '%Y-%m-%d') \n",
    "    except:\n",
    "        print(file_name)\n",
    "        exercise_dates = ''\n",
    "        \n",
    "    evaluation = int(meta[2].replace('eval', ''))\n",
    "    flag_before_surgery = int(meta[3].replace('bf', '').replace('.csv', ''))\n",
    "    return {\n",
    "        'patient_id': patient_id,\n",
    "        'exercise_dates': exercise_dates.strftime('%Y-%m-%d'),\n",
    "        'evaluation': evaluation,\n",
    "        'flag_before_surgery': flag_before_surgery,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48b85966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_excercise(directory, filename):   \n",
    "    file_meta = filename_to_metadata(file_name)\n",
    "    \n",
    "    patient_id = file_meta['patient_id']\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(directory, filename))\n",
    "    df.drop(['patient', 'date', 'before surgery', 'evaluation'], axis = 1, inplace = True)\n",
    "    \n",
    "    #error handlin in original data, to catch which file has error uncomment this\n",
    "    #errorrs_in_exercise_ = df[[not isinstance(value, str) for value in df['exercise']]]\n",
    "    #if len(errorrs_in_exercise_):\n",
    "    #    print(filename)\n",
    "    #    print(errorrs_in_exercise_)\n",
    "    \n",
    "    exercises = sorted(df['exercise'].astype(str).unique())\n",
    "\n",
    "    pois = sorted(df['point id'].unique())\n",
    "    session = {\n",
    "        'meta': file_meta,\n",
    "        'exercises': []\n",
    "    }\n",
    "    \n",
    "    for exercise in exercises:\n",
    "        df_exercise = df[(df['exercise'] == exercise)]\n",
    "        \n",
    "        exercise_data = {\n",
    "            'meta': {\n",
    "                'tag': exercise,\n",
    "                'id': int(exercise.split('_')[0]),\n",
    "                'name': exercise.split('_')[1]\n",
    "            },\n",
    "            'pois': [],\n",
    "        }\n",
    "\n",
    "        for poi in pois: \n",
    "            df_poi = df_exercise[(df_exercise['point id']) == poi]\n",
    "            df_poi = df_poi.sort_values(by=['t'])\n",
    "            df_poi = df_poi.drop(columns = ['exercise', 'point id'], axis=1)\n",
    "            \n",
    "            ts = df_poi['t'].tolist()\n",
    "            xs = df_poi['x'].tolist()\n",
    "            ys = df_poi['y'].tolist()\n",
    "            zs = df_poi['z'].tolist()\n",
    "            \n",
    "            poi_data = {\n",
    "                'meta': {\n",
    "                    'tag': poi,\n",
    "                    'id': int(poi.split('_')[0]),\n",
    "                    'name': poi.split('_')[1],  \n",
    "                    'region': region[poi],\n",
    "                    'base': base[poi]\n",
    "                },\n",
    "                'input': {\n",
    "                    'ts': ts,\n",
    "                    'xs': xs,\n",
    "                    'ys': ys,\n",
    "                    'zs': zs,\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            exercise_data['pois'].append(poi_data)\n",
    "            \n",
    "        session['exercises'].append(exercise_data)\n",
    "        \n",
    "    return patient_id, session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab6ece",
   "metadata": {},
   "source": [
    "Read every file in the target directory and apply mapper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256cd9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000078\n",
      "00000000000\n",
      "00000000055\n",
      "00000000041\n",
      "00000000015\n",
      "00000000067\n",
      "00000000070\n",
      "00000000016\n",
      "00000000065\n",
      "00000000019\n",
      "00000000003\n",
      "00000000007\n",
      "00000000038\n",
      "00000000014\n",
      "00000000047\n",
      "00000000039\n",
      "00000000002\n",
      "00000000042\n",
      "00000000036\n",
      "00000000023\n",
      "00000000035\n",
      "00000000068\n",
      "00000000010\n",
      "00000000011\n",
      "00000000040\n",
      "00000000029\n",
      "00000000046\n",
      "00000000045\n",
      "00000000028\n",
      "00000000072\n",
      "00000000076\n",
      "00000000026\n",
      "00000000052\n",
      "00000000018\n",
      "00000000057\n",
      "00000000001\n",
      "00000000017\n",
      "00000000025\n",
      "00000000059\n",
      "00000000080\n",
      "00000000081\n",
      "00000000048\n",
      "00000000064\n",
      "00000000033\n",
      "00000000006\n",
      "00000000082\n",
      "00000000083\n",
      "00000000063\n",
      "00000000009\n",
      "00000000069\n",
      "00000000060\n",
      "00000000012\n",
      "00000000073\n",
      "00000000053\n",
      "00000000066\n",
      "00000000027\n",
      "00000000020\n",
      "00000000074\n",
      "00000000051\n",
      "00000000030\n",
      "00000000031\n",
      "00000000085\n",
      "00000000061\n",
      "00000000071\n",
      "00000000056\n",
      "00000000004\n",
      "00000000005\n",
      "00000000050\n",
      "00000000079\n",
      "00000000049\n",
      "00000000034\n",
      "00000000044\n",
      "00000000008\n",
      "00000000043\n",
      "00000000013\n",
      "00000000077\n",
      "00000000022\n",
      "00000000037\n",
      "00000000058\n",
      "00000000075\n",
      "00000000032\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for file_name in os.listdir(dir_data_source):\n",
    "    \n",
    "    patient_id, session = file_to_excercise(dir_data_source, file_name) \n",
    "    \n",
    "    if patient_id not in data:\n",
    "        data[patient_id] = []\n",
    "    data[patient_id].append(session)    \n",
    "\n",
    "\n",
    "for patient_id in data:\n",
    "    print(patient_id)\n",
    "    with open(os.path.join(dir_data_target, '%s.json' % patient_id), \"w\") as f_w:\n",
    "        json.dump(data[patient_id], f_w)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde8e3db",
   "metadata": {},
   "source": [
    "__END__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face-prognosis",
   "language": "python",
   "name": "face-prognosis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
