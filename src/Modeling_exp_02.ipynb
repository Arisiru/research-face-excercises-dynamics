{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ffceac",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941fce85",
   "metadata": {},
   "source": [
    "First iteration is to model: goal to have end to end pipeline from data to dynamics for a patient\n",
    "- Don't have test train split\n",
    "- Predict on training data\n",
    "- Entry is an exercise\n",
    "- Include exercise meta like https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2167fbdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2277c",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb75db30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SEQ_MAX_LEN = 600\n",
    "NUM_CLASSES = 6\n",
    "NUM_EXERCISES = 9\n",
    "NUM_FLAG_BS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed45b66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_data_root = os.path.join('..', 'data')\n",
    "dir_exercises = os.path.join(dir_data_root, 'json', 'exercises_raw')\n",
    "dir_exercises_augmented = os.path.join(dir_data_root, 'json', 'exercises_augmented')\n",
    "dir_patiens_sessions = os.path.join(dir_data_root, 'json', 'patients_sessions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544c090",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca3d18d",
   "metadata": {},
   "source": [
    "### Build training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6fe59eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\n",
    "    'frontal',\n",
    "    'orbital',\n",
    "    'oral'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd41d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = {\n",
    "    '0_LefteyeMidbottom': 'orbital', \n",
    "    '1_LefteyeMidtop': 'orbital',  \n",
    "    '2_LefteyeInnercorner': 'orbital', \n",
    "    '3_LefteyeOutercorner': 'orbital',  \n",
    "    '4_LefteyebrowInner': 'frontal', \n",
    "    '5_LefteyebrowCenter': 'frontal',  \n",
    "    '6_RighteyeMidbottom': 'orbital',  \n",
    "    '7_RighteyeMidtop': 'orbital', \n",
    "    '8_RighteyeInnercorner': 'orbital',  \n",
    "    '9_RighteyeOutercorner': 'orbital', \n",
    "    '10_RighteyebrowInner': 'frontal', \n",
    "    '11_RighteyebrowCenter': 'frontal',  \n",
    "    '12_NoseTip': 'frontal', \n",
    "    '13_MouthLowerlipMidbottom': 'oral',\n",
    "    '14_MouthLeftcorner': 'oral',\n",
    "    '15_MouthRightcorner': 'oral',\n",
    "    '16_MouthUpperlipMidtop': 'oral',\n",
    "    '17_ChinCenter': 'oral', \n",
    "    '18_ForeheadCenter': 'frontal', \n",
    "    '19_LeftcheekCenter': 'oral', \n",
    "    '20_RightcheekCenter': 'oral',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8b45114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_region(pois, region):\n",
    "    exercise_sequence_region = []\n",
    "    \n",
    "    for poi in sorted(pois.keys()):\n",
    "        if regions[poi] != region: continue\n",
    "        \n",
    "        sequences = pois[poi]\n",
    "        exercise_sequence_region.append(sequences['xs'])\n",
    "        exercise_sequence_region.append(sequences['ys'])\n",
    "        exercise_sequence_region.append(sequences['zs'])\n",
    "\n",
    "    exercise_sequence_region = pad_sequences(\n",
    "        exercise_sequence_region,\n",
    "        padding=\"pre\",\n",
    "        maxlen=SEQ_MAX_LEN)\n",
    "        \n",
    "    return exercise_sequence_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d508f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def exercise_to_input(file_path):\n",
    "    with open(file_path, 'r') as f_r:\n",
    "        exercise = json.load(f_r)\n",
    "        \n",
    "        # build global\n",
    "        exercise_sequence_global_region = []\n",
    "\n",
    "        for poi in sorted(exercise['pois'].keys()):\n",
    "            sequences = exercise['pois'][poi]\n",
    "            exercise_sequence_global_region.append(sequences['xs'])\n",
    "            exercise_sequence_global_region.append(sequences['ys'])\n",
    "            exercise_sequence_global_region.append(sequences['zs'])\n",
    "    \n",
    "        exercise_sequence_global_region = pad_sequences(\n",
    "            exercise_sequence_global_region,\n",
    "            padding=\"pre\",\n",
    "            maxlen=SEQ_MAX_LEN)\n",
    "        \n",
    "        # build regions \n",
    "        exercise_sequence_frontal_region = build_region(exercise['pois'], 'frontal')\n",
    "        exercise_sequence_oral_region = build_region(exercise['pois'], 'oral')\n",
    "        exercise_sequence_orbital_region = build_region(exercise['pois'], 'orbital')\n",
    "        \n",
    "    # build meta\n",
    "    x_a_1 = [0] * NUM_EXERCISES\n",
    "    x_a_2 = [0] * NUM_FLAG_BS\n",
    "    x_a_1[exercise['meta']['id']] = 1\n",
    "    x_a_2[exercise['meta']['flag_before_surgery']] = 1\n",
    "\n",
    "    return [\n",
    "            x_a_1 + x_a_2, \n",
    "            exercise_sequence_global_region, \n",
    "            exercise_sequence_frontal_region,\n",
    "            exercise_sequence_oral_region,\n",
    "            exercise_sequence_orbital_region,\n",
    "            exercise['meta']['evaluation']\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a93a7a24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10740,)\n",
      "(10740, 11)\n",
      "(10740, 63, 600)\n",
      "(10740, 18, 600)\n",
      "(10740, 21, 600)\n",
      "(10740, 24, 600)\n"
     ]
    }
   ],
   "source": [
    "xslist_meta = list()\n",
    "xslist_global = list()\n",
    "xslist_frontal = list()\n",
    "xslist_oral = list()\n",
    "xslist_orbital = list()\n",
    "yslist = list()\n",
    "\n",
    "exercises_sources = [\n",
    "    dir_exercises,\n",
    "    dir_exercises_augmented\n",
    "]\n",
    "\n",
    "for exercise_source in exercises_sources:\n",
    "    for file_name in os.listdir(exercise_source):\n",
    "        file_path = os.path.join(exercise_source, file_name)\n",
    "\n",
    "        if file_name == '.DS_Store': continue\n",
    "\n",
    "        _xs_meta, _xs_global, _xs_frontal, _xs_oral, _xs_orbital, _ys = exercise_to_input(file_path)\n",
    "\n",
    "        yslist.append(_ys)\n",
    "        xslist_meta.append(_xs_meta)  \n",
    "        xslist_global.append(_xs_global)\n",
    "        xslist_frontal.append(_xs_frontal)\n",
    "        xslist_oral.append(_xs_oral)\n",
    "        xslist_orbital.append(_xs_orbital)\n",
    "        #break\n",
    "            \n",
    "ys = np.array(yslist)\n",
    "xs_meta = np.array(xslist_meta)   \n",
    "xs_global = np.array(xslist_global) \n",
    "xs_frontal = np.array(xslist_frontal) \n",
    "xs_oral = np.array(xslist_oral) \n",
    "xs_orbital = np.array(xslist_orbital) \n",
    "\n",
    "print(ys.shape)\n",
    "print(xs_meta.shape)\n",
    "print(xs_global.shape)\n",
    "print(xs_frontal.shape)\n",
    "print(xs_oral.shape)\n",
    "print(xs_orbital.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab6ea1d4",
   "metadata": {},
   "source": [
    "was \n",
    "(1029,)\n",
    "(1029, 11)\n",
    "(1029, 63, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeba3312",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db63f1bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f06345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dnn(inputLayer): \n",
    "    m = Dense(4, activation=\"relu\")(inputLayer)\n",
    "    m = Model(inputs=inputLayer, outputs=m)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc36a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn(inputLayer):\n",
    "    chanDim = -1\n",
    "    \n",
    "    m = Conv1D(16, 3, padding='same', activation='relu')(inputLayer)\n",
    "    m = BatchNormalization(axis=chanDim)(m)\n",
    "    m = MaxPooling1D((2))(m)\n",
    "    m = Conv1D(32, 3, padding='same', activation='relu')(m)\n",
    "    m = BatchNormalization(axis=chanDim)(m)\n",
    "    m = MaxPooling1D((2))(m)\n",
    "    m = Conv1D(64, 3, padding='same', activation='relu')(m)\n",
    "    m = BatchNormalization(axis=chanDim)(m)\n",
    "    m = MaxPooling1D((2))(m)\n",
    "    m = Conv1D(64, 3, padding='same', activation='relu')(m)\n",
    "    m = BatchNormalization(axis=chanDim)(m)\n",
    "    m = MaxPooling1D((2))(m)\n",
    "    m = Flatten()(m)\n",
    "    m = Dropout(0.5)(m)\n",
    "    m = Dense(128, activation=\"relu\")(m)\n",
    "    m = Model(inputs=inputLayer, outputs=m)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29b2c732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_meta = Input(shape=xs_meta.shape[1:])\n",
    "    model_meta = get_dnn(input_meta)\n",
    "    \n",
    "    input_global = Input(shape=xs_global.shape[1:])\n",
    "    model_global = get_cnn(input_global)\n",
    "    \n",
    "    input_frontal = Input(shape=xs_frontal.shape[1:])\n",
    "    model_frontal = get_cnn(input_frontal)  \n",
    "\n",
    "    input_oral = Input(shape=xs_oral.shape[1:])\n",
    "    model_oral = get_cnn(input_oral)  \n",
    "    \n",
    "    input_orbital = Input(shape=xs_orbital.shape[1:])\n",
    "    model_orbital = get_cnn(input_orbital)  \n",
    "    \n",
    "    \n",
    "    model_contatenate = concatenate([\n",
    "        model_meta.output, \n",
    "        model_global.output,\n",
    "        model_frontal.output,\n",
    "        model_oral.output,\n",
    "        model_orbital.output,\n",
    "    ])\n",
    "    \n",
    "    model_contatenate = Dense(32, activation=\"relu\")(model_contatenate)\n",
    "    model_contatenate = Dense(6, activation=\"softmax\")(model_contatenate)\n",
    "    model = Model(inputs=[\n",
    "        model_meta.input,\n",
    "        model_global.input,\n",
    "        model_frontal.input,\n",
    "        model_oral.input,\n",
    "        model_orbital.input\n",
    "    ], outputs=model_contatenate)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", \n",
    "        optimizer=Adam(learning_rate=1e-3, decay=1e-3 / 200),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2377d19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 08:45:56.627369: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-06-17 08:45:56.627525: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 63, 600)]    0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 18, 600)]    0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 21, 600)]    0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 24, 600)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 63, 16)       28816       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 18, 16)       28816       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 21, 16)       28816       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 24, 16)       28816       ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 63, 16)      64          ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 18, 16)      64          ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 21, 16)      64          ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 24, 16)      64          ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 31, 16)       0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 9, 16)       0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 10, 16)      0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_12 (MaxPooling1D  (None, 12, 16)      0           ['batch_normalization_12[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 31, 32)       1568        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 9, 32)        1568        ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 10, 32)       1568        ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 12, 32)       1568        ['max_pooling1d_12[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 31, 32)      128         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 9, 32)       128         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 10, 32)      128         ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 12, 32)      128         ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 15, 32)      0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 4, 32)       0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_9 (MaxPooling1D)  (None, 5, 32)       0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_13 (MaxPooling1D  (None, 6, 32)       0           ['batch_normalization_13[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 15, 64)       6208        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 4, 64)        6208        ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 5, 64)        6208        ['max_pooling1d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 6, 64)        6208        ['max_pooling1d_13[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 15, 64)      256         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 4, 64)       256         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_10 (BatchN  (None, 5, 64)       256         ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 6, 64)       256         ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 7, 64)       0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 2, 64)       0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_10 (MaxPooling1D  (None, 2, 64)       0           ['batch_normalization_10[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_14 (MaxPooling1D  (None, 3, 64)       0           ['batch_normalization_14[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 7, 64)        12352       ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 2, 64)        12352       ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 2, 64)        12352       ['max_pooling1d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 3, 64)        12352       ['max_pooling1d_14[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 7, 64)       256         ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 2, 64)       256         ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 2, 64)       256         ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 3, 64)       256         ['conv1d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 3, 64)       0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 1, 64)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_11 (MaxPooling1D  (None, 1, 64)       0           ['batch_normalization_11[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_15 (MaxPooling1D  (None, 1, 64)       0           ['batch_normalization_15[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 192)          0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 64)           0           ['max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 64)           0           ['max_pooling1d_11[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 64)           0           ['max_pooling1d_15[0][0]']       \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 11)]         0           []                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 192)          0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 64)           0           ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 64)           0           ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4)            48          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          24704       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          8320        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          8320        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          8320        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 516)          0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]',                \n",
      "                                                                  'dense_2[0][0]',                \n",
      "                                                                  'dense_3[0][0]',                \n",
      "                                                                  'dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 32)           16544       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 6)            198         ['dense_5[0][0]']                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 265,046\n",
      "Trainable params: 263,638\n",
      "Non-trainable params: 1,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_model = get_model()\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82dd2364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "print(set(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1bca9ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight_training_classes = {0: 0.32075471698113206, \n",
    "                           1: 1.1333333333333333,\n",
    "                           2: 1.3076923076923077, \n",
    "                           3: 3.4, \n",
    "                           4: 3.4,\n",
    "                           5: 1.5454545454545454}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accfe635",
   "metadata": {},
   "source": [
    "### K-fold evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c142f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "train = 0.8\n",
    "val = 0.2\n",
    "test = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aacb4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = 0\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f377532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f442eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_indx(k, n):\n",
    "\n",
    "    k_fold = KFold(n_splits=k)\n",
    "    train_ = []\n",
    "    val_ = []\n",
    "    test_ = []\n",
    "    indx = []\n",
    "\n",
    "    for train_indices, test_indices in k_fold.split(ys):\n",
    "        n_k = len(train_indices)\n",
    "        val_split = int(n_k * train)\n",
    "        indx.append([train_indices[:val_split],train_indices[val_split + 1:], test_indices])\n",
    "    \n",
    "    return indx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf2f0ddd",
   "metadata": {},
   "source": [
    "print(get_k_indx(k, len(ys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ebf4216",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 08:45:58.982472: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-06-17 08:46:01.050177: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-17 08:46:47.124846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-17 11:12:39.410840: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       964\n",
      "           1       0.88      0.99      0.93       347\n",
      "           2       0.96      0.99      0.98       352\n",
      "           3       0.99      1.00      1.00       124\n",
      "           4       0.98      1.00      0.99       126\n",
      "           5       0.99      1.00      0.99       235\n",
      "\n",
      "    accuracy                           0.97      2148\n",
      "   macro avg       0.97      0.99      0.98      2148\n",
      "weighted avg       0.97      0.97      0.97      2148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 11:12:46.724598: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-17 11:13:35.227741: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-17 13:37:17.974657: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       967\n",
      "           1       0.96      0.98      0.97       337\n",
      "           2       0.96      0.99      0.97       347\n",
      "           3       0.91      1.00      0.95       128\n",
      "           4       0.97      0.98      0.98       129\n",
      "           5       0.97      0.99      0.98       240\n",
      "\n",
      "    accuracy                           0.97      2148\n",
      "   macro avg       0.96      0.98      0.97      2148\n",
      "weighted avg       0.97      0.97      0.97      2148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 13:37:26.400763: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-17 13:38:18.291677: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-17 16:06:09.524879: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       961\n",
      "           1       0.94      0.98      0.96       357\n",
      "           2       0.93      0.99      0.96       357\n",
      "           3       0.86      0.99      0.92       120\n",
      "           4       0.94      0.99      0.96       123\n",
      "           5       0.96      0.96      0.96       230\n",
      "\n",
      "    accuracy                           0.95      2148\n",
      "   macro avg       0.94      0.97      0.95      2148\n",
      "weighted avg       0.96      0.95      0.95      2148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 16:06:17.304279: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-17 16:07:10.677020: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-17 18:34:46.708187: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       960\n",
      "           1       0.99      0.95      0.97       356\n",
      "           2       0.88      0.99      0.93       358\n",
      "           3       0.99      0.93      0.96       120\n",
      "           4       0.94      0.96      0.95       124\n",
      "           5       1.00      0.97      0.98       230\n",
      "\n",
      "    accuracy                           0.97      2148\n",
      "   macro avg       0.96      0.96      0.96      2148\n",
      "weighted avg       0.97      0.97      0.97      2148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 18:34:56.215052: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-17 18:35:54.561866: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-17 21:04:03.977866: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       968\n",
      "           1       0.99      0.97      0.98       338\n",
      "           2       0.93      0.99      0.96       346\n",
      "           3       0.98      0.98      0.98       128\n",
      "           4       0.97      0.96      0.96       128\n",
      "           5       1.00      0.97      0.98       240\n",
      "\n",
      "    accuracy                           0.97      2148\n",
      "   macro avg       0.97      0.97      0.97      2148\n",
      "weighted avg       0.98      0.97      0.97      2148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indxs = get_k_indx(k, len(ys))\n",
    "\n",
    "for i in range(k):\n",
    "    train_indx, val_indx, test_indx  = indxs[i]\n",
    "    xs_meta_i = xs_meta[train_indx]\n",
    "    xs_meta_i_val = xs_meta[val_indx]\n",
    "    xs_meta_i_test = xs_meta[test_indx]\n",
    "    \n",
    "    xs_global_i = xs_global[train_indx]\n",
    "    xs_global_i_val = xs_global[val_indx]\n",
    "    xs_global_i_test = xs_global[test_indx]\n",
    "    \n",
    "    xs_frontal_i = xs_frontal[train_indx]\n",
    "    xs_frontal_i_val = xs_frontal[val_indx]\n",
    "    xs_frontal_i_test = xs_frontal[test_indx]\n",
    "    \n",
    "    xs_oral_i = xs_oral[train_indx]\n",
    "    xs_oral_i_val = xs_oral[val_indx]\n",
    "    xs_oral_i_test = xs_oral[test_indx]\n",
    "    \n",
    "    xs_orbital_i = xs_orbital[train_indx]\n",
    "    xs_orbital_i_val = xs_orbital[val_indx]\n",
    "    xs_orbital_i_test = xs_orbital[test_indx]\n",
    "    \n",
    "    ys_i = ys[train_indx]\n",
    "    ys_i_val = ys[val_indx]\n",
    "    ys_i_test = ys[test_indx]\n",
    "\n",
    "    model = get_model()\n",
    "\n",
    "    model.fit(\n",
    "        x=[\n",
    "            xs_meta_i, \n",
    "            xs_global_i, \n",
    "            xs_frontal_i,\n",
    "            xs_oral_i,\n",
    "            xs_orbital_i], y=ys_i, \n",
    "        validation_data=([\n",
    "            xs_meta_i_val,\n",
    "            xs_global_i_val,\n",
    "            xs_frontal_i_val,\n",
    "            xs_oral_i_val,\n",
    "            xs_orbital_i_val], ys_i_val),\n",
    "        batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "        class_weight=weight_training_classes,\n",
    "        verbose=VERBOSE)\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_pred = model.predict([\n",
    "        xs_meta_i_test,\n",
    "        xs_global_i_test,\n",
    "        xs_frontal_i_test,\n",
    "        xs_oral_i_test,\n",
    "        xs_orbital_i_test],verbose=0)\n",
    "    y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    print(classification_report(ys_i_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9a00ea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mStop\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Stop' is not defined"
     ]
    }
   ],
   "source": [
    "Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d8951e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "statistics.mean([0.98, 0.97, 0.95, 0.96, 0.97])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7657fdf8",
   "metadata": {},
   "source": [
    "# Patient dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07b130f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from operator import attrgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85421a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('_mpl-gallery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79494615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = [1.0, 2.0, 4.0, 8.0, 16.0, 32.0]\n",
    "exercises_number = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8bc919",
   "metadata": {},
   "source": [
    "## Single patient with details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc3df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patient_id = '00000000020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e15f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sessions = []\n",
    "with open(os.path.join(dir_patiens_sessions, '%s.json' % patient_id), 'r') as f_r:\n",
    "    sessions = json.load(f_r)\n",
    "    \n",
    "print(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4fae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sessions.sort(key=lambda x: x['exercise_dates'])\n",
    "print(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16880c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dynamic = []\n",
    "evaluations = []\n",
    "\n",
    "for session in sessions:\n",
    "    exercises_result = []\n",
    "    print(session['evaluation'] + 1) #from index to class\n",
    "    evaluations.append(session['evaluation'] + 1)\n",
    "\n",
    "    fig, axs = plt.subplots(1,9,figsize=(15,2)) \n",
    "\n",
    "    for exercise_id in range(exercises_number):\n",
    "        file_name = os.path.join(\n",
    "            dir_exercises, '%s_%s_%s.json' % (\n",
    "                patient_id, \n",
    "                session['id'],\n",
    "                exercise_id))\n",
    "        \n",
    "        if not os.path.isfile(file_name):\n",
    "            continue\n",
    "            \n",
    "        xs_a, xs_b, ys = exercise_to_input(file_name)\n",
    "        \n",
    "        xs_a = np.array([xs_a])   \n",
    "        xs_b = np.array([xs_b]) \n",
    "        \n",
    "        #print(xs_a.shape)\n",
    "        #print(xs_b.shape)\n",
    "        \n",
    "        \n",
    "        y_pred = model.predict([xs_a, xs_b], verbose=0)\n",
    "        exercises_result.append(list(y_pred[0]))\n",
    "        \n",
    "                \n",
    "        axs[exercise_id].bar(1 + np.arange(6), y_pred[0], width=1, edgecolor=\"white\", linewidth=0.7)\n",
    "\n",
    "        axs[exercise_id].set(\n",
    "            xlim=(0, 7), \n",
    "            xticks=np.arange(1, 7),\n",
    "            ylim=(0, 1))\n",
    "    \n",
    "    #average session \n",
    "    prediction = np.average(np.array(exercises_result), axis=0)\n",
    "    exercise_score = [y*w for y, w in zip(prediction,weights)]\n",
    "    dynamic.append(sum(exercise_score))\n",
    "    \n",
    "    fig, axs = plt.subplots(1,2,figsize=(4,2)) \n",
    "        \n",
    "    x = 1 + np.arange(6)\n",
    "    y_pred = y_pred[0]\n",
    "    y_score = exercise_score\n",
    "\n",
    "    axs[0].bar(x, y_pred, width=1, edgecolor=\"white\", linewidth=0.7)\n",
    "\n",
    "    axs[0].set(xlim=(0, 7), \n",
    "              xticks=np.arange(1, 7),\n",
    "              ylim=(0, 1), \n",
    "             )\n",
    "\n",
    "\n",
    "    axs[1].bar(x, y_score, width=1, edgecolor=\"white\", linewidth=0.7)\n",
    "    axs[1].set(xlim=(0, 7), \n",
    "              xticks=np.arange(1, 7),\n",
    "              ylim=(0, max(y_score) + 1), \n",
    "             )\n",
    "\n",
    "    plt.show()    \n",
    "        \n",
    "\n",
    "print(dynamic)\n",
    "fig, ax = plt.subplots(figsize=(4,2)) \n",
    "\n",
    "x = 1 + np.arange(len(sessions))\n",
    "y = dynamic\n",
    "\n",
    "#ax.bar(x, y, width=1, edgecolor=\"white\", linewidth=0.7)\n",
    "ax.plot(x, y, color='tab:blue')\n",
    "ax.bar(x, evaluations, color='tab:orange', edgecolor=\"white\", linewidth=0.7)\n",
    "\n",
    "ax.set(xlim=(0, len(sessions) + 1), \n",
    "          xticks=np.arange(1, len(sessions) + 1),\n",
    "          ylim=(0, max(7, max(y) + 1)), \n",
    "         )\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af1fedb",
   "metadata": {},
   "source": [
    "## Patients Dynamics: Multiple Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653be2ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_fine_score(patient_id):\n",
    "    sessions = []\n",
    "    fine_score = []\n",
    "    evaluations = []\n",
    "\n",
    "    with open(os.path.join(dir_patiens_sessions, '%s.json' % patient_id), 'r') as f_r:\n",
    "        sessions = json.load(f_r)\n",
    "        \n",
    "    sessions.sort(key=lambda x: x['exercise_dates'])\n",
    "    \n",
    "    for session in sessions:\n",
    "        exercises_result = []\n",
    "        evaluations.append(session['evaluation'] + 1)\n",
    "    \n",
    "        for exercise_id in range(exercises_number):\n",
    "            file_name = os.path.join(\n",
    "                dir_exercises, '%s_%s_%s.json' % (\n",
    "                    patient_id, \n",
    "                    session['id'],\n",
    "                    exercise_id))\n",
    "\n",
    "            if not os.path.isfile(file_name):\n",
    "                continue\n",
    "\n",
    "            xs_a, xs_b, ys = exercise_to_input(file_name)\n",
    "\n",
    "            xs_a = np.array([xs_a])   \n",
    "            xs_b = np.array([xs_b]) \n",
    "\n",
    "            y_pred = model.predict([xs_a, xs_b], verbose=0)\n",
    "            exercises_result.append(list(y_pred[0]))\n",
    "\n",
    "        #average session \n",
    "        prediction = np.average(np.array(exercises_result), axis=0)\n",
    "        exercise_score = [y*w for y, w in zip(prediction,weights)]\n",
    "        fine_score.append(sum(exercise_score))\n",
    "        \n",
    "    return fine_score, evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d27222",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patients = [\n",
    "    '00000000034',\n",
    "    '00000000074',\n",
    "    '00000000058',\n",
    "    '00000000039',\n",
    "    '00000000081',\n",
    "    '00000000042',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0787a6b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for patient_id in patients:\n",
    "    fine_score, evaluations = get_fine_score(patient_id)\n",
    "    fig, ax = plt.subplots(figsize=(4,2)) \n",
    "\n",
    "    x = 1 + np.arange(len(evaluations))\n",
    "\n",
    "    ax.plot(x, fine_score, color='tab:blue', marker='D')\n",
    "    ax.bar(x, evaluations, color='tab:orange', edgecolor='white', linewidth=0.7)\n",
    "\n",
    "    ax.set(\n",
    "        xlim=(0, len(sessions) + 1), \n",
    "        xticks=np.arange(1, len(sessions) + 1),\n",
    "        ylim=(0, max(7, max(fine_score) + 1)),\n",
    "        xlabel='Sessions',\n",
    "        ylabel='Scores',\n",
    "        title='%s: HB scores %s ' % (patient_id, ', '.join(map(str, evaluations)))\n",
    "    )\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde8e3db",
   "metadata": {},
   "source": [
    "__END__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf7298",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face-prognosis",
   "language": "python",
   "name": "face-prognosis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
