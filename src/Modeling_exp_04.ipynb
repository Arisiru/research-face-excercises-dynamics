{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ffceac",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddd4f2",
   "metadata": {},
   "source": [
    "Fourth iteration of the modeling:\n",
    "- modulirized data processing\n",
    "- model serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2167fbdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import math\n",
    "from itertools import chain\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('_mpl-gallery')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2277c",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb75db30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SEQ_MAX_LEN = 600\n",
    "NUM_CLASSES = 6\n",
    "NUM_EXERCISES = 9\n",
    "NUM_FLAG_BS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed45b66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_root = os.path.join('..')\n",
    "dir_data_root = os.path.join(dir_root, 'data')\n",
    "dir_exercises = os.path.join(dir_data_root, 'json', 'exercises_raw')\n",
    "dir_exercises_test = os.path.join(dir_data_root, 'json', 'exercises_test')\n",
    "dir_exercises_augmented = os.path.join(dir_data_root, 'json', 'exercises_augmented')\n",
    "dir_patiens_sessions = os.path.join(dir_data_root, 'json', 'patients_sessions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544c090",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca3d18d",
   "metadata": {},
   "source": [
    "### Build training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31de161",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup, exercise_to_input\n",
      "File \u001b[0;32m~/Projects/Research/research-face-excercises-dynamics/src/utils/input.py:8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformations\u001b[39;00m\n\u001b[1;32m     10\u001b[0m CONFIG \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(root_path, seq_max_len, num_exercises, num_flag_bs):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformations'"
     ]
    }
   ],
   "source": [
    "from utils.input import setup, exercise_to_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup(os.path.join('..'), SEQ_MAX_LEN, NUM_EXERCISES, NUM_FLAG_BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa3579",
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises_sources = [\n",
    "    dir_exercises_test\n",
    "    #dir_exercises,\n",
    "    #dir_exercises_augmented\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b845ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineering_setting = {\n",
    "    'coordinates': True,\n",
    "    'normalize_by_start': False,\n",
    "    'normalize': False,\n",
    "    'direction': True,\n",
    "    'distance': True,\n",
    "    're_base': True,\n",
    "    'transformation_to_rebase': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93a7a24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xslist_meta = list()\n",
    "xslist_global = list()\n",
    "xslist_frontal = list()\n",
    "xslist_oral = list()\n",
    "xslist_orbital = list()\n",
    "yslist = list()\n",
    "\n",
    "for exercise_source in exercises_sources:\n",
    "    for file_name in os.listdir(exercise_source):\n",
    "        file_path = os.path.join(exercise_source, file_name)\n",
    "\n",
    "        if file_name == '.DS_Store': continue\n",
    "\n",
    "        _xs_meta, _xs_global, _xs_frontal, _xs_oral, _xs_orbital, _ys = exercise_to_input(file_path, feature_engineering_setting)\n",
    "\n",
    "        yslist.append(_ys)\n",
    "        xslist_meta.append(_xs_meta)  \n",
    "        xslist_global.append(_xs_global)\n",
    "        xslist_frontal.append(_xs_frontal)\n",
    "        xslist_oral.append(_xs_oral)\n",
    "        xslist_orbital.append(_xs_orbital)\n",
    "            \n",
    "ys = np.array(yslist)\n",
    "xs_meta = np.array(xslist_meta)   \n",
    "xs_global = np.array(xslist_global) \n",
    "xs_frontal = np.array(xslist_frontal) \n",
    "xs_oral = np.array(xslist_oral) \n",
    "xs_orbital = np.array(xslist_orbital) \n",
    "\n",
    "print(ys.shape)\n",
    "print(xs_meta.shape)\n",
    "print(xs_global.shape)\n",
    "print(xs_frontal.shape)\n",
    "print(xs_oral.shape)\n",
    "print(xs_orbital.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "284e8e04",
   "metadata": {},
   "source": [
    "print(xs_orbital)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeba3312",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db63f1bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f06345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dnn(inputLayer): \n",
    "    m = Dense(4, activation=\"relu\")(inputLayer)\n",
    "    m = Model(inputs=inputLayer, outputs=m)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc36a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn(inputLayer):\n",
    "    chanDim = -1\n",
    "    \n",
    "    m = Conv1D(16, 3, padding='same', activation='relu')(inputLayer)\n",
    "    m = BatchNormalization(axis=chanDim)(m)\n",
    "    m = MaxPooling1D((2))(m)\n",
    "    m = Conv1D(32, 3, padding='same', activation='relu')(m)\n",
    "    m = BatchNormalization(axis=chanDim)(m)\n",
    "    m = MaxPooling1D((2))(m)\n",
    "    m = Conv1D(64, 3, padding='same', activation='relu')(m)\n",
    "    m = BatchNormalization(axis=chanDim)(m)\n",
    "    m = MaxPooling1D((2))(m)\n",
    "    m = Conv1D(64, 3, padding='same', activation='relu')(m)\n",
    "    m = BatchNormalization(axis=chanDim)(m)\n",
    "    m = MaxPooling1D((2))(m)\n",
    "    m = Flatten()(m)\n",
    "    m = Dropout(0.5)(m)\n",
    "    m = Dense(128, activation=\"relu\")(m)\n",
    "    m = Model(inputs=inputLayer, outputs=m)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2c732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_meta = Input(shape=xs_meta.shape[1:])\n",
    "    model_meta = get_dnn(input_meta)\n",
    "    \n",
    "    input_global = Input(shape=xs_global.shape[1:])\n",
    "    model_global = get_cnn(input_global)\n",
    "    \n",
    "    input_frontal = Input(shape=xs_frontal.shape[1:])\n",
    "    model_frontal = get_cnn(input_frontal)  \n",
    "\n",
    "    input_oral = Input(shape=xs_oral.shape[1:])\n",
    "    model_oral = get_cnn(input_oral)  \n",
    "    \n",
    "    input_orbital = Input(shape=xs_orbital.shape[1:])\n",
    "    model_orbital = get_cnn(input_orbital)  \n",
    "    \n",
    "    \n",
    "    model_contatenate = concatenate([\n",
    "        model_meta.output, \n",
    "        model_global.output,\n",
    "        model_frontal.output,\n",
    "        model_oral.output,\n",
    "        model_orbital.output,\n",
    "    ])\n",
    "    \n",
    "    model_contatenate = Dense(32, activation=\"relu\")(model_contatenate)\n",
    "    model_contatenate = Dense(6, activation=\"softmax\")(model_contatenate)\n",
    "        \n",
    "    model = Model(inputs=[\n",
    "        model_meta.input,\n",
    "        model_global.input,\n",
    "        model_frontal.input,\n",
    "        model_oral.input,\n",
    "        model_orbital.input\n",
    "    ], outputs=model_contatenate)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", \n",
    "        optimizer=Adam(learning_rate=1e-3, decay=1e-3 / 200),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = get_model()\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd2364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(set(ys))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dada9459",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "weight_training_classes = {0: 0.32075471698113206, \n",
    "                           1: 1.1333333333333333,\n",
    "                           2: 1.3076923076923077, \n",
    "                           3: 3.4, \n",
    "                           4: 3.4,\n",
    "                           5: 1.5454545454545454}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accfe635",
   "metadata": {},
   "source": [
    "### K-fold evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c142f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "k_limit = 5\n",
    "train = 0.8\n",
    "val = 0.2\n",
    "test = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aacb4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = 0\n",
    "EPOCHS = 400\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f377532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f442eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_indx(k, n):\n",
    "\n",
    "    k_fold = KFold(n_splits=k)\n",
    "    train_ = []\n",
    "    val_ = []\n",
    "    test_ = []\n",
    "    indx = []\n",
    "\n",
    "    for train_indices, test_indices in k_fold.split(ys):\n",
    "        n_k = len(train_indices)\n",
    "        val_split = int(n_k * train)\n",
    "        indx.append([train_indices[:val_split],train_indices[val_split + 1:], test_indices])\n",
    "    \n",
    "    return indx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9cbc755e",
   "metadata": {},
   "source": [
    "print(get_k_indx(k, len(ys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "indxs = get_k_indx(k, len(ys))\n",
    "models = []\n",
    "\n",
    "for i in range(k_limit):\n",
    "    train_indx, val_indx, test_indx  = indxs[i]\n",
    "    xs_meta_i = xs_meta[train_indx]\n",
    "    xs_meta_i_val = xs_meta[val_indx]\n",
    "    xs_meta_i_test = xs_meta[test_indx]\n",
    "    \n",
    "    xs_global_i = xs_global[train_indx]\n",
    "    xs_global_i_val = xs_global[val_indx]\n",
    "    xs_global_i_test = xs_global[test_indx]\n",
    "    \n",
    "    xs_frontal_i = xs_frontal[train_indx]\n",
    "    xs_frontal_i_val = xs_frontal[val_indx]\n",
    "    xs_frontal_i_test = xs_frontal[test_indx]\n",
    "    \n",
    "    xs_oral_i = xs_oral[train_indx]\n",
    "    xs_oral_i_val = xs_oral[val_indx]\n",
    "    xs_oral_i_test = xs_oral[test_indx]\n",
    "    \n",
    "    xs_orbital_i = xs_orbital[train_indx]\n",
    "    xs_orbital_i_val = xs_orbital[val_indx]\n",
    "    xs_orbital_i_test = xs_orbital[test_indx]\n",
    "    \n",
    "    ys_i = ys[train_indx]\n",
    "    ys_i_val = ys[val_indx]\n",
    "    ys_i_test = ys[test_indx]\n",
    "    \n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                 classes = np.unique(ys_i),\n",
    "                                                 y=ys_i)\n",
    "    available_classes = np.unique(ys_i)\n",
    "    weight_training_classes = {\n",
    "        0: 0,\n",
    "        1: 0,\n",
    "        2: 0,\n",
    "        3: 0,\n",
    "        4: 0,\n",
    "        5: 0,\n",
    "    }\n",
    "    \n",
    "    for indx, value in enumerate(class_weights):\n",
    "        weight_training_classes[available_classes[indx]] = value\n",
    "\n",
    "    #print(weight_training_classes)\n",
    "\n",
    "    model = get_model()\n",
    "\n",
    "    model_callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "    ]\n",
    "    \n",
    "    hist = model.fit(\n",
    "        x=[\n",
    "            xs_meta_i, \n",
    "            xs_global_i, \n",
    "            xs_frontal_i,\n",
    "            xs_oral_i,\n",
    "            xs_orbital_i], y=ys_i, \n",
    "        validation_data=([\n",
    "            xs_meta_i_val,\n",
    "            xs_global_i_val,\n",
    "            xs_frontal_i_val,\n",
    "            xs_oral_i_val,\n",
    "            xs_orbital_i_val], ys_i_val),\n",
    "        batch_size=BATCH_SIZE, \n",
    "        epochs=EPOCHS,\n",
    "        class_weight=weight_training_classes,\n",
    "        #callbacks=model_callbacks,\n",
    "        verbose=VERBOSE)\n",
    "    \n",
    "    models.append(model)\n",
    "    \n",
    "    # visualizing losses and accuracy\n",
    "    train_loss = hist.history['loss']\n",
    "    val_loss   = hist.history['val_loss']\n",
    "    train_acc  = hist.history['accuracy']\n",
    "    val_acc    = hist.history['val_accuracy']\n",
    "    xc         = range(len(hist.history['loss']))    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(f'Run {i}')\n",
    "    plt.plot(xc, train_loss, color='red')\n",
    "    plt.plot(xc, val_loss, color='pink')\n",
    "    plt.plot(xc, train_acc, color='blue')\n",
    "    plt.plot(xc, val_acc, color='cyan')\n",
    "    \n",
    "    y_pred = model.predict([\n",
    "        xs_meta_i_test,\n",
    "        xs_global_i_test,\n",
    "        xs_frontal_i_test,\n",
    "        xs_oral_i_test,\n",
    "        xs_orbital_i_test],verbose=0)\n",
    "    y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    print(classification_report(ys_i_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9e0ddd",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Model Serialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a54ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize = False\n",
    "best_model = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa64468",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_models = os.path.join(dir_root, 'models')\n",
    "dir_model = os.path.join(dir_models, 'type4-with-fe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba5cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if serialize:\n",
    "    model = models[best_model]\n",
    "    model.save(dir_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e7a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face-prognosis",
   "language": "python",
   "name": "face-prognosis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
